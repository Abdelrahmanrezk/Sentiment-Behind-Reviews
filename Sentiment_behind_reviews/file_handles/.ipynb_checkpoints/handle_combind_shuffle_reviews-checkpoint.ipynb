{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reviews Handling\n",
    "based on the problems of Sentimen Classifcation some of reviews file have muliple columns like:\n",
    "- 'reviews.dateAdded' \n",
    "- 'reviews.dateSeen'\n",
    "- others columns\n",
    "\n",
    "but we just interset in two columns the text review and the rate of each review.\n",
    "\n",
    "So here is a function that handle these problems and return the reviews with two columns.\n",
    "\n",
    "**Another Function to compine the returned data frames to one data frame:**\n",
    "combine_positive_negative_reviews this function is to handle returned data frame as just one data frame with the two columns\n",
    "\n",
    "**Another Function to shuffle the reviews of the returned combined data frame**\n",
    "\n",
    "**Another Function to convert the data frame to csv file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviews_handling function\n",
    "\n",
    "A function below handle files that contain multiple of columns but we need the reviews and the rate of each reviews, but based on rate we return that all of reviews > 3 is positive other wise is negative which <= 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reviews_handling(data_frame, review_column , rating_column):\n",
    "    '''\n",
    "   Argument:\n",
    "       data frame of file\n",
    "   return:\n",
    "       data frame with two columns one of text review second is 1 positive or 0 negative\n",
    "    '''\n",
    "    positive_reviews = df[df[rating_column] > 3]\n",
    "    print(\"We have \" + str(len(positive_reviews)) + \" positive Reviews\")\n",
    "    negative_reviews = df[df[rating_column] <= 3]\n",
    "    print(\"We have \" + str(len(negative_reviews)) + \" negative Reviews\")\n",
    "\n",
    "# Now get the text reviews for each index and its rate\n",
    "    positive_reviews = positive_reviews.loc[:, [review_column, rating_column]]\n",
    "    negative_reviews = negative_reviews.loc[:, [review_column, rating_column]]\n",
    "    positive_reviews[rating_column] = 1\n",
    "    negative_reviews[rating_column] = 0\n",
    "# you will see in the print how looks like the rate of each review as we change\n",
    "\n",
    "    print(\"Now We have just the needed columns from the data frame\", positive_reviews[:5])\n",
    "    print(\"#\"*80)\n",
    "    print(\"Now We have just the needed columns from the data frame\", negative_reviews[:5])\n",
    "    return positive_reviews, negative_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_positive_negative_reviews(positive_reviews, negative_reviews):\n",
    "    '''\n",
    "    Arguments:\n",
    "        2 data frames each with 2 columns\n",
    "    return:\n",
    "        one data frame contain the two column\n",
    "    \n",
    "    '''\n",
    "    combined_dfs = pd.concat([positive_reviews,negative_reviews], ignore_index=True)\n",
    "    print(\"The compined data frame \", combined_dfs[:5])\n",
    "    print(\"The compined data frame \", combined_dfs[-5:-1]) # two show negatives also\n",
    "# next we have a function that shuffle these reviews because of future work\n",
    "    return combined_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv('../csv_files/1429_1.csv')\n",
    "    os.remove('../csv_files/1429_1.csv')\n",
    "except Exception as e:\n",
    "    file = open(\"../logs_files/file_read_error.log\",\"+a\")\n",
    "    file.write(\"\\n\" \n",
    "               + str(e) + \"\\n\" + \"#\" *99 + \"\\n\") # \"#\" *99 as separated lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the line below return a data frame with 2 columns for each varaibles \n",
    "# text reviews and positive or negative as 1,0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    positive_reviews, negative_reviews = reviews_handling(df, 'reviews.text', 'reviews.rating')\n",
    "    first_combined = combine_positive_negative_reviews(positive_reviews, negative_reviews)\n",
    "except Exception as e:\n",
    "    file = open(\"../logs_files/reviews_handling.log\",\"+a\")\n",
    "    file.write(\"\\n\" \n",
    "               + str(e) + \"\\n\" + \"#\" *99 + \"\\n\") # \"#\" *99 as separated lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read another file\n",
    "try:\n",
    "    df = pd.read_csv('../csv_files/Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products.csv') \n",
    "    os.remove('../csv_files/Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products.csv')\n",
    "    len(df)\n",
    "except Exception as e:\n",
    "    file = open(\"../logs_files/file_read_error.log\",\"+a\")\n",
    "    file.write(\"\\n\" \n",
    "               + str(e) + \"\\n\" + \"#\" *99 + \"\\n\") # \"#\" *99 as separated lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    positive_reviews, negative_reviews = reviews_handling(df, 'reviews.text', 'reviews.rating')\n",
    "    second_combine = combine_positive_negative_reviews(positive_reviews, negative_reviews)\n",
    "    aggregation_combined = combine_positive_negative_reviews(first_combined, second_combine)\n",
    "except Exception as e:\n",
    "    file = open(\"../logs_files/reviews_handling.log\",\"+a\")\n",
    "    file.write(\"\\n\" \n",
    "               + str(e) + \"\\n\" + \"#\" *99 + \"\\n\") # \"#\" *99 as separated lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read another file\n",
    "try:\n",
    "    df = pd.read_csv('../csv_files/Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products_May19.csv') \n",
    "    os.remove('../csv_files/Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products_May19.csv')\n",
    "    len(df)\n",
    "except Exception as e:\n",
    "    file = open(\"../logs_files/file_read_error.log\",\"+a\")\n",
    "    file.write(\"\\n\" \n",
    "               + str(e) + \"\\n\" + \"#\" *99 + \"\\n\") # \"#\" *99 as separated lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    positive_reviews, negative_reviews = reviews_handling(df, 'reviews.text', 'reviews.rating')\n",
    "    third_combine = combine_positive_negative_reviews(positive_reviews, negative_reviews)\n",
    "    aggregation_combined = combine_positive_negative_reviews(aggregation_combined, third_combine)\n",
    "except Exception as e:\n",
    "    file = open(\"../logs_files/reviews_handling.log\",\"+a\")\n",
    "    file.write(\"\\n\" \n",
    "               + str(e) + \"\\n\" + \"#\" *99 + \"\\n\") # \"#\" *99 as separated lines\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle all reviews\n",
    "def shuffle_dataframe_of_reviews(df):\n",
    "    '''\n",
    "        A function return one data fram but with shuffled rows\n",
    "    '''\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    aggregation_combined_shuffled = shuffle_dataframe_of_reviews(aggregation_combined)\n",
    "    print(aggregation_combined[:20]) # now you can see before shuffle\n",
    "    print(aggregation_combined_shuffled[:20]) # and you can see after shuffle\n",
    "    currentDT = str(datetime.datetime.now())\n",
    "    currentDT\n",
    "    aggregation_combined_shuffled.to_csv('../csv_files/last_time_combined_reviews_' + currentDT +'.csv', index=False)\n",
    "    df = pd.read_csv('../csv_files/last_time_combined_reviews_' + currentDT +'.csv')\n",
    "    print(df.head())\n",
    "except Exception as e:\n",
    "    file = open(\"../logs_files/shuffle_dataframe_of_reviews.log\",\"+a\")\n",
    "    file.write(\"\\n\" \n",
    "               + str(e) + \"\\n\" + \"#\" *99 + \"\\n\") # \"#\" *99 as separated lines\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function below to handle reviews\n",
    "because of sometimes I classified handlabel reviews, so the file has more than 20 thounsand of reviews, so each time i classified some of these reviews need to append to other classified file for using later then remove these classified reviews from the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_classifed_reviews(file_reviews, \n",
    "                             file_classified_reviews, number_of_classifed_reviews):\n",
    "    '''\n",
    "    Arguments:\n",
    "        file reviews: this file has some of reviews classified but not all so,\n",
    "        number_of_classifed_reviews: we send to cut from and append to,\n",
    "        file_classified_reviews: which has all of classifed reviews\n",
    "    return classified file, file_reviews after cuting the number_of_classifed_reviews from it\n",
    "    '''\n",
    "# get classifed reviews\n",
    "    df_classifed_reviews = file_reviews[:number_of_classifed_reviews]\n",
    "    df_classifed_reviews.dropna(inplace=True) # may some of rows are empty\n",
    "    df_classifed_reviews = df_classifed_reviews.reset_index(drop=True)\n",
    "# resave file after cut classifed reviews\n",
    "    file_reviews = file_reviews.drop(file_reviews.index[:number_of_classifed_reviews])\n",
    "    file_reviews = file_reviews.reset_index(drop=True)\n",
    "    file_reviews.to_csv('../csv_files/all_file_reviews.csv',index = False, header=True)\n",
    "    \n",
    "# append classified reviews to classifed file\n",
    "    file_classified_reviews = file_classified_reviews.append(df_classifed_reviews)\n",
    "    file_classified_reviews = file_classified_reviews.reset_index(drop=True)\n",
    "    file_classified_reviews.to_csv('../csv_files/file_classified_reviews.csv', index = False, header=True)\n",
    "    return file_reviews, file_classified_reviews\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
