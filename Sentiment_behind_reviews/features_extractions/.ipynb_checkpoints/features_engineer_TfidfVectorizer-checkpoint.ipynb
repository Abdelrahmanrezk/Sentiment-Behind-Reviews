{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word counts like CountVectorizer are a good starting point, but are very basic.**\n",
    "\n",
    "One of the problem related to this is counts words like “the, and, or, there and others\" will appear many times and their large counts will not be very meaningful in the encoded vectors and cause our model to missunderstand important words than those repeated many times.\n",
    "\n",
    "Alternative way of this is to calculate word frequencies which the first of tfidf is tf--> Term Frequency, then  down scale these words that appear a lot across documents using the second part which is idf --> Inverse Document Frequency.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pymongo\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# splitting data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Features Extraction\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cleaning data file because of using some of its function of we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our scraped now are 5777 Product\n",
      "one product Data\n",
      "\n",
      " {'_id': ObjectId('5e48539b980cc3c34837af7f'), 'product_title': 'هاتف ابل ايفون 11 مع فيس تايم بشريحة واحدة وشريحة الكترونية - ذاكرة تخزين 64 جيجا، ذاكرة وصول عشوائية 4 جيجا، شبكة ال تي اي من الجيل الرابع - ارجواني', 'product_url': 'https://egypt.souq.com/eg-ar/%D9%87%D8%A7%D8%AA%D9%81-%D8%A7%D8%A8%D9%84-%D8%A7%D9%8A%D9%81%D9%88%D9%86-11-%D9%85%D8%B9-%D9%81%D9%8A%D8%B3-%D8%AA%D8%A7%D9%8A%D9%85-%D8%A8%D8%B4%D8%B1%D9%8A%D8%AD%D8%A9-%D9%88%D8%A7%D8%AD%D8%AF%D8%A9-%D9%88%D8%B4%D8%B1%D9%8A%D8%AD%D8%A9-%D8%A7%D9%84%D9%83%D8%AA%D8%B1%D9%88%D9%86%D9%8A%D8%A9-%D8%B0%D8%A7%D9%83%D8%B1%D8%A9-%D8%AA%D8%AE%D8%B2%D9%8A%D9%86-64-%D8%AC%D9%8A%D8%AC%D8%A7-%D8%B0%D8%A7%D9%83%D8%B1%D8%A9-%D9%88%D8%B5%D9%88%D9%84-%D8%B9%D8%B4%D9%88%D8%A7%D8%A6%D9%8A%D8%A9-4-%D8%AC%D9%8A%D8%AC%D8%A7-%D8%B4%D8%A8%D9%83%D8%A9-%D8%A7%D9%84-%D8%AA%D9%8A-%D8%A7%D9%8A-%D9%85%D9%86-%D8%A7%D9%84%D8%AC%D9%8A%D9%84-%D8%A7%D9%84%D8%B1%D8%A7%D8%A8%D8%B9-%D8%A7%D8%B1%D8%AC%D9%88%D8%A7%D9%86%D9%8A-68312948/i/', 'image_src': 'https://cf1.s3.souqcdn.com/item/2019/09/12/68/31/29/48/item_L_68312948_63bd51c18418a.jpg', 'product_new_price': 14299.0, 'product_old_price': 0.0, 'product_discount_percentage': 0.0, 'product_discount_value': 0.0, 'product_reviews': ['جهاز رائع', 'ممتاز', 'جهاز ما يحتاج تقييم', 'توصيل سريع وسعر ممتاز', 'السلام عليكم ورحمة الله وبركاته لقد تم إيصال الجوال الايفون ولم تصلني الشريحة الإلكترونية أرجو الإفادة', 'ممتاز والتوصيل مره سريع', 'كل شئ يجنن تغليف ممتاز توصيل سريع سعر رائع شكرا سوق', 'شكرا السعر وربي ببلاش كمان وصل سريع', 'المنتج أصلي وسعره منافس وأقل من التطبيقات الأخرى المنتج أصلي وسعره منافس وأقل من التطبيقات الأخرى المنتج أصلي وسعره منافس وأقل من التطبيقات الأخرى', 'لا يوجد', 'Loved', 'يعطيهم العافيه الجهاز وصل سليم وممتاز', 'ممتاز جدا', 'مطابق للمواصفات و سرعه فى التوصيل', 'مثل ما هو مكتوب والتوصيل في الموعد', 'جميييييل', 'ممتاز والسعر كويس', 'رائع', 'صراحة كنت خايفة يطلع مو اصلي لكن الحمدلله طلع اصلي١٠٠٪\\u061c والسعر منافس جدا', 'جميل', 'ممتاز', 'هاتف جميل وأنيق', 'صراحه جوده فاشله جدا', 'منتج اصلي وتوصيل رائع', 'جميل جدا انصح به', 'ممتاز', 'ممتاز جدا وسرعه بخدمة الشحن', 'شكرا لسوق ع السعر الرايع', 'المنتج اصلي ولا يوجد اي ملاحظات وتم توصيله بسرعة شكراً', 'ممتاز', 'الجهاز معروف والتوصيل في الموعد شكراً لكم', 'السعر كان جداً جميل ، التوصيل سريع', 'perfect and delivered within 1 day', 'Good', 'Just changed from Samsung s9 to this , so good to be an iPhone user, build quality is excellent', 'Original .. Thanks', 'السعر رائع والتوصيل سريع جدا', 'At first I was so worried and suspicious, but once it arrived I checked the serial number and it’s as original as it can be, very good, packaging was well done, and the device is amazing', 'I love it and delivery is too fast', 'وصل تاني يوم من الطلب شكرا سوق'], 'main_feature_of_product': ['2019-09-13', '16.4 centimeters', '512 grams', '190199222397', 'ابل', 'iOS', '64 جيجابايت', 'Dual SIM (nano-SIM and eSIM)', 'هواتف ذكية', '4جي ال تي اي', 'ابل', 'MWLX2AH/A', '2000 - 3000 مللي أمبير_ساعة', 'UPC-A', '190199222397', '2724968977898', '12MP Ultra Wide + 12 MP Wide', '6.1 انش', 'ارجواني', '4 جيجابايت'], 'Uploaded_product': False}\n",
      "First File\n",
      " 156\n",
      "\n",
      "After Expanding two file together\n",
      " 889\n",
      "\n",
      "Remove Dublicated words\n",
      " 661\n",
      "\n",
      "Update the end file manually to remove some of words\n",
      " 525\n",
      "Total Arabic reviews\n",
      " 38695\n",
      "\n",
      "Total English reviews\n",
      " 34166\n",
      "\n",
      "Some of  Arabic reviews\n",
      " ['جهاز ممتاز و تسليم من سوق فوق الممتاز', 'ممتاز شكراً لسوق كوم وللبائع وتوصيل سريع أيضا', 'شيء خرافي', 'ابداع جديد من سامسونج', 'لايوجد']\n",
      "\n",
      "some of English reviews\n",
      " ['I love it', 'soug really doing good service to society | compare to the local market the prices are very less - minimum 5%', 'Faster delivery ,genuine product. ..Cheaper in price as compare to any other online shopping. Must try this seller...Thanks Souq..', 'Genuine Product', 'Nothing']\n",
      "Now Total Arabic reviews\n",
      " 20494\n",
      "\n",
      "Now Total English reviews\n",
      " 18950\n",
      "Now Total Arabic reviews\n",
      " 19870\n",
      "\n",
      "Now Total English reviews\n",
      " 18220\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(os.path.abspath('../scraping_cleaning'))\n",
    "from cleaning_data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read our classified file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arabic Reviews</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ممتاز صراح مريح خاصت في خرج لي من غير عرب</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>عمل</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>جيد وع</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>حل</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>سرير او محجر كما سمي ممتاز وم عب امان خاص اطفا...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Arabic Reviews  polarity\n",
       "0         ممتاز صراح مريح خاصت في خرج لي من غير عرب          1\n",
       "1                                               عمل          1\n",
       "2                                            جيد وع          0\n",
       "3                                                حل          1\n",
       "4  سرير او محجر كما سمي ممتاز وم عب امان خاص اطفا...         1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_file = pd.read_csv('../csv_files/file_classified_reviews_updated.csv')\n",
    "df_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of reviews in our data set is:  6057\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of reviews in our data set is: \", len(df_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shuffle the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file = df_file.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arabic Reviews</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>جيد حجم سط ليس بير شكل نفس</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>منتج صل ضم ممتاز</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>صراح ناس غا في ادب نشاط</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>برامج العاب تنزل على ذاكره داخليه صغيره جيج لي...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>موبايل ممتاز خام ممتاز جوانب من معدن سعر رخص م...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Arabic Reviews  polarity\n",
       "0                        جيد حجم سط ليس بير شكل نفس          0\n",
       "1                                  منتج صل ضم ممتاز          1\n",
       "2                           صراح ناس غا في ادب نشاط          1\n",
       "3  برامج العاب تنزل على ذاكره داخليه صغيره جيج لي...         1\n",
       "4  موبايل ممتاز خام ممتاز جوانب من معدن سعر رخص م...         1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now \n",
    "df_file.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split the data to train and testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_file['Arabic Reviews'] \n",
    "y = df_file['polarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96                 نصح بها عمل جد مريح لكن ضعيف لي حد ما \n",
       "3437             ثاب جد راءع ممتاز ذات راءح واح جد روووع \n",
       "312                                    مع جد في ضوء نهار \n",
       "5582    رام 4GB ذاكر بير قدر حط ذاكر خارج 400GB كثر من...\n",
       "1612                             حجم صغر من جوال ايف بلس \n",
       "Name: Arabic Reviews, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.1)\n",
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our training data now are: 5451 Reviews\n",
      "Our testing data now are: 606 Reviews\n",
      "Our training data now are: 5451 labels\n",
      "Our testing data now are: 606 labels\n"
     ]
    }
   ],
   "source": [
    "print(\"Our training data now are: \" + str(len(X_train))  + \" Reviews\")\n",
    "print(\"Our testing data now are: \" + str(len(X_test))  + \" Reviews\")\n",
    "print(\"Our training data now are: \" + str(len(y_train))  + \" labels\")\n",
    "print(\"Our testing data now are: \" + str(len(y_test))  + \" labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take object from TfidfVectorizer & fit the data\n",
    "The CountVectorizer provides a simple way to both tokenize a **collection of text documents** like:\n",
    "![example of data](../images/TfidfVectorizer_df_file.png)\n",
    "\n",
    "\n",
    "and build a vocabulary of known words, but also to encode new documents using that vocabulary like:\n",
    "![example of output](../images/TfidfVectorizervocabulary_.png)\n",
    "\n",
    "**The inverse document frequencies are calculated for each word in the vocabulary, assigning the lowest score of 1.0 to the most frequently observed word: \"the\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_vectorizer(df):\n",
    "    '''\n",
    "    Argumen:\n",
    "        df dataframe of multiple reviews\n",
    "    return:\n",
    "        Train & test arrays that can fir to the model\n",
    "    '''\n",
    "# I fit the vector to all of the data\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_vectorizer = tfidf_vectorizer.fit(X) \n",
    "    word_idf_weights = tfidf_vectorizer.idf_\n",
    "    print(\"Our 10 words weights\\n\\n\",word_idf_weights[:10])\n",
    "# fit splited data\n",
    "    testing_data = tfidf_vectorizer.transform(X_test)\n",
    "    training_data = tfidf_vectorizer.transform(X_train) \n",
    "# convert to array that can apply to ML model\n",
    "    training_data = training_data.toarray()\n",
    "    testing_data = testing_data.toarray()\n",
    "    return training_data, testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our 10 words weights\n",
      "\n",
      " [9.01598781 9.01598781 7.07007766 6.49025917 9.01598781 9.01598781\n",
      " 9.01598781 8.32284063 9.01598781 9.01598781]\n"
     ]
    }
   ],
   "source": [
    "training_data, testing_data = tfidf_vectorizer(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our new vectorized data: (5451, 5464)\n",
      "Our new vectorized data: (606, 5464)\n",
      "The first 2 review after transform: \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# first shape is the data itself and second shape is the BOW in our data\n",
    "print(\"Our new vectorized data: \" + str(training_data.shape))\n",
    "print(\"Our new vectorized data: \" + str(testing_data.shape)) \n",
    "print(\"The first 2 review after transform: \\n\", testing_data[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### result using naive_bayes MultinomialNB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_MultinomialNB = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clf_MultinomialNB.fit(training_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of our training data is:  0.8460832874701889\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 score of our training data is: \", f1_score(y_train, predict, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evalution Matrix of training data is \n",
      " [[ 211  837]\n",
      " [   2 4401]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Evalution Matrix of training data is \\n\", confusion_matrix(y_train, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of our testing data is:  0.8415841584158416\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 score of our testing data is: \", f1_score(y_test, predict, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evalution Matrix of training data is \n",
      " [[ 10  96]\n",
      " [  0 500]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Evalution Matrix of training data is \\n\", confusion_matrix(y_test, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### result using LogisticRegression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_LogisticRegression = LogisticRegression(penalty='l2', tol=0.00001, solver='liblinear',max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = clf_LogisticRegression.fit(training_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = logistic_model.predict(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of our testing data is:  0.8985507246376812\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 score of our testing data is: \", f1_score(y_train, predict, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evalution Matrix of training data is \n",
      " [[ 539  509]\n",
      " [  44 4359]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Evalution Matrix of training data is \\n\", confusion_matrix(y_train, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = logistic_model.predict(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of our testing data is:  0.9042904290429042\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 score of our testing data is: \", f1_score(y_test, predict, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evalution Matrix of training data is \n",
      " [[ 54  52]\n",
      " [  6 494]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Evalution Matrix of training data is \\n\", confusion_matrix(y_test, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### result using SVC Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_SVC = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = clf_SVC.fit(training_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = svc_model.predict(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of our testing data is:  0.9308383782792148\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 score of our testing data is: \", f1_score(y_train, predict, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evalution Matrix of training data is \n",
      " [[ 727  321]\n",
      " [  56 4347]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Evalution Matrix of training data is \\n\", confusion_matrix(y_train, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = svc_model.predict(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of our testing data is:  0.9075907590759076\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 score of our testing data is: \", f1_score(y_test, predict, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evalution Matrix of training data is \n",
      " [[ 61  45]\n",
      " [ 11 489]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Evalution Matrix of training data is \\n\", confusion_matrix(y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_SVC = SVC(kernel='poly', degree=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdelrahman/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "svc_model = clf_SVC.fit(training_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = svc_model.predict(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of our training data is:  0.8077416987708678\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 score of our training data is: \", f1_score(y_train, predict, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evalution Matrix of training data is \n",
      " [[   0 1048]\n",
      " [   0 4403]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Evalution Matrix of training data is \\n\", confusion_matrix(y_train, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = svc_model.predict(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of our testing data is:  0.8250825082508251\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 score of our testing data is: \", f1_score(y_test, predict, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evalution Matrix of testing data is \n",
      " [[  0 106]\n",
      " [  0 500]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Evalution Matrix of testing data is \\n\", confusion_matrix(y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_SVC = SVC(kernel='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdelrahman/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "svc_model = clf_SVC.fit(training_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = svc_model.predict(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of our training data is:  0.8077416987708678\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 score of our training data is: \", f1_score(y_train, predict, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = svc_model.predict(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of our testing data is:  0.8250825082508251\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 score of our testing data is: \", f1_score(y_test, predict, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evalution Matrix of testing data is \n",
      " [[  0 106]\n",
      " [  0 500]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Evalution Matrix of testing data is \\n\", confusion_matrix(y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
